# -*- coding: utf-8 -*-
"""UAS PEMBELAJARAN MESIN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qQH41b5fZdD__qcB0DvfQCsF0OQmAQjM
"""

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

df = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')
df.head()

#3. Data Preprocessing
#  a) Data Cleaning


# Menghapus kolom id (tidak berpengaruh ke prediksi)
df.drop('id', axis=1, inplace=True)

# Mengisi missing value pada kolom bmi dengan median
df['bmi'].fillna(df['bmi'].median(), inplace=True)

from sklearn.preprocessing import LabelEncoder
# b) Encoding Data Kategorikal
categorical_cols = [
    'gender', 'ever_married', 'work_type',
    'Residence_type', 'smoking_status'
]

le = LabelEncoder()
for col in categorical_cols:
    df[col] = le.fit_transform(df[col])

#c) Normalisasi / Standarisasi

X = df.drop('stroke', axis=1)
y = df['stroke']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 4. Split Data
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

from sklearn.ensemble import RandomForestClassifier

#5. Implementasi Model (SEBELUM TUNING)
knn = KNeighborsClassifier()
dt = DecisionTreeClassifier(random_state=42)
svm = SVC()

knn.fit(X_train, y_train)
dt.fit(X_train, y_train)
svm.fit(X_train, y_train)

#6. Hyperparameter Tuning
#KKN
param_knn = {
    'n_neighbors': [3,5,7],
    'weights': ['uniform', 'distance']
}

grid_knn = GridSearchCV(KNeighborsClassifier(), param_knn, cv=5)
grid_knn.fit(X_train, y_train)

knn_best = grid_knn.best_estimator_

#Decision Tree
param_dt = {
    'max_depth': [5,10,20],
    'min_samples_split': [2,5,10]
}

grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_dt, cv=5)
grid_dt.fit(X_train, y_train)

dt_best = grid_dt.best_estimator_

#SVM
param_svm = {
    'C': [0.1,1,10],
    'kernel': ['linear', 'rbf']
}

grid_svm = GridSearchCV(SVC(), param_svm, cv=5)
grid_svm.fit(X_train, y_train)

svm_best = grid_svm.best_estimator_

#7. Evaluasi Performa Model
def evaluate_model(name, y_test, y_pred):
    return {
        "Model": name,
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred, zero_division=0),
        "Recall": recall_score(y_test, y_pred),
        "F1-score": f1_score(y_test, y_pred)
    }

results = []

results.append(evaluate_model("KNN", y_test, knn_best.predict(X_test)))
results.append(evaluate_model("Decision Tree", y_test, dt_best.predict(X_test)))
results.append(evaluate_model("SVM", y_test, svm_best.predict(X_test)))

df_results = pd.DataFrame(results)
df_results

df_results.round(3)

dt = DecisionTreeClassifier(random_state=42, class_weight='balanced')
svm = SVC(class_weight='balanced')

import matplotlib.pyplot as plt
import numpy as np

# Nama model
models = ['KNN', 'Decision Tree', 'SVM']

# Akurasi sebelum dan sesudah tuning
accuracy_awal = [0.949, 0.947, 0.951]
accuracy_tuning = [0.816, 0.797, 0.741]

x = np.arange(len(models))
width = 0.35

plt.figure()
plt.bar(x - width/2, accuracy_awal, width, label='Sebelum Tuning')
plt.bar(x + width/2, accuracy_tuning, width, label='Setelah Tuning')

plt.xticks(x, models)
plt.ylabel('Accuracy')
plt.title('Perbandingan Akurasi Model Sebelum dan Sesudah Tuning')
plt.legend()

plt.show()